# system configuration
hadoop_bin=/Users/frai/Programs/hadoop-2.4.1/bin/hadoop # path to the hadoop executable
base_path=/Users/frai/Programs/fdr_parallel # complete path to the 'BoW_package' folder
m=2 # number of mappers to be used (set with the number automaticaly defined by Hadoop)
r=2 # number of reducers to be used
Sr=0.01 # sampling ratio for SnI

# dataset configuration
dataset=synthetic_hadoop.dat # dataset name
dimensionality=15 # dataset dimensionality
size=100000 # dataset size (total number of points)
input=hdfs/$dataset/ # complete path in the HDFS file system to the data files

# initial wall-clock time meassurement
initialTime="$(date +%s)"

echo "Compiling jar..."
javac packFDR/RecordReaderFDR.java packFDR/InputFormatFDR.java packFDR/testMapper.java packFDR/testReducer.java -cp hadoop-core-1.2.1.jar
jar cf libFDR.jar packFDR

cd $base_path/ParC
make spotless
make

rm -f dimensionality
echo $dimensionality > dimensionality
rm -f size
echo $size > size
rm -f divisions
echo $r > divisions

$hadoop_bin fs -rm -r ParC
$hadoop_bin fs -mkdir ParC

rm -r -f ../results/$dataset
mkdir -p ../results/$dataset/output_parallel_$r

echo "Running Hadoop..."
#$hadoop_bin jar ../myHadoopStreaming.jar -libjars ../libFDR.jar -D mapreduce.task.timeout=0 fs.local.block.size=1048576 -inputformat packFDR.InputFormatFDR -mapper packFDR.testMapper -file dimensionality -file size -file divisions -file parameters -input $input -output ParC/output/ -numReduceTasks $r
$hadoop_bin jar ../myHadoopStreaming.jar -libjars ../libFDR.jar -D mapreduce.task.timeout=0 fs.local.block.size=1048576 -inputformat packFDR.InputFormatFDR -mapper mapper -reducer reducer -file mapper -file reducer -file dimensionality -file size -file divisions -file parameters -input $input -output ParC/output/ -numReduceTasks $r
echo "Finished"

$hadoop_bin fs -get ParC/output/* ../results/$dataset/output_parallel_$r/
$hadoop_bin fs -rm -r ParC

# final wall-clock time meassurement
totalTime=`echo "$(date +%s) - $initialTime" | bc -l`
echo $totalTime > ../results/$dataset/output_parallel_$r/time

#cleanup
echo "Cleaning..."
make spotless
rm -f dimensionality
rm -f size
rm -f divisions
rm -f sample
rm -f part-00000